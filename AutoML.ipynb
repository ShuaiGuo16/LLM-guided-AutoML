{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d223ad",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we will use AutoML library to address the NSL-KDD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212942b",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea05a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171085",
   "metadata": {},
   "source": [
    "#### 1.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20011b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train data\n",
    "train = pd.read_csv('dataset/train_AutoML_probe.csv')\n",
    "train.rename(columns={'attack_category': 'attack'}, inplace=True)\n",
    "\n",
    "# import test data\n",
    "test = pd.read_csv('dataset/test_AutoML_probe.csv')\n",
    "test.rename(columns={'attack_category': 'attack'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a00f8b",
   "metadata": {},
   "source": [
    "#### 1.2 Feature category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bd94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = defaultdict(list)\n",
    "with open('dataset/feature_types.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        feature, category = line.strip().strip('.').split(': ')\n",
    "        feature_names[category].append(feature)\n",
    "\n",
    "# continuous features\n",
    "continuous_features = feature_names['continuous']\n",
    "continuous_features.remove('num_outbound_cmds')\n",
    "\n",
    "# binary features\n",
    "binary_features = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "\n",
    "# nominal features\n",
    "nominal_features = list(set(feature_names['discrete'])-set(binary_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3fd20c",
   "metadata": {},
   "source": [
    "#### 1.3 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad941b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "train[nominal_features] = enc.fit_transform(train[nominal_features])\n",
    "test[nominal_features] = enc.transform(test[nominal_features])\n",
    "\n",
    "# Separate feature/label\n",
    "X_train, y_train = train.iloc[:, :-1].to_numpy(), train.iloc[:, -1].to_numpy()\n",
    "X_test, y_test = test.iloc[:, :-1].to_numpy(), test.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbafed",
   "metadata": {},
   "source": [
    "### 2. ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87162774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    accuracy_score, \n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "\n",
    "def metrics_display(y_test, y_pred, y_pred_proba):\n",
    "\n",
    "    # Obtain confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Output classification metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f'ROC_AUC score: {roc_auc_score(y_test, y_pred_proba):.3f}')\n",
    "    print(f'f1 score: {f1_score(y_test, y_pred):.3f}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'Detection rate: {recall_score(y_test, y_pred)*100:.2f}%')\n",
    "    print(f'False alarm rate: {fp / (tn+fp)*100}%')\n",
    "    print(f'MCC: {matthews_corrcoef(y_test, y_pred):.2f}')\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, y_pred, values_format='.5g', colorbar=False)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591da9f2",
   "metadata": {},
   "source": [
    "#### 2.1 Default XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "clf_xgb = xgb.XGBClassifier(eval_metric='auc', \n",
    "                            max_depth=4,\n",
    "                            learning_rate=0.3,\n",
    "                            reg_lambda=50,\n",
    "                            gamma=5,\n",
    "                            subsample=1,\n",
    "                            colsample_bytree=1,\n",
    "                            use_label_encoder=False,\n",
    "                            scale_pos_weight=50,\n",
    "                            n_jobs=-1,\n",
    "                            seed=42)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "y_pred_proba = clf_xgb.predict_proba(X_test)[:, 1]\n",
    "metrics_display(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146813a",
   "metadata": {},
   "source": [
    "#### 2.2 AutoML with FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cebb72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-16 17:46:28] {2373} INFO - task = classification\n",
      "[flaml.automl: 09-16 17:46:28] {2375} INFO - Data split method: stratified\n",
      "[flaml.automl: 09-16 17:46:28] {2379} INFO - Evaluation method: cv\n",
      "[flaml.automl: 09-16 17:46:28] {2448} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 09-16 17:46:28] {2586} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl: 09-16 17:46:28] {2878} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:29] {3008} INFO - Estimated sufficient time budget=14005s. Estimated necessary time budget=14s.\n",
      "[flaml.automl: 09-16 17:46:29] {3055} INFO -  at 1.5s,\testimator xgboost's best error=0.0139,\tbest estimator xgboost's best error=0.0139\n",
      "[flaml.automl: 09-16 17:46:29] {2878} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:30] {3055} INFO -  at 2.1s,\testimator xgboost's best error=0.0074,\tbest estimator xgboost's best error=0.0074\n",
      "[flaml.automl: 09-16 17:46:30] {2878} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:30] {3055} INFO -  at 2.9s,\testimator xgboost's best error=0.0074,\tbest estimator xgboost's best error=0.0074\n",
      "[flaml.automl: 09-16 17:46:30] {2878} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:31] {3055} INFO -  at 3.6s,\testimator xgboost's best error=0.0074,\tbest estimator xgboost's best error=0.0074\n",
      "[flaml.automl: 09-16 17:46:31] {2878} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:32] {3055} INFO -  at 4.3s,\testimator xgboost's best error=0.0074,\tbest estimator xgboost's best error=0.0074\n",
      "[flaml.automl: 09-16 17:46:32] {2878} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:33] {3055} INFO -  at 5.0s,\testimator xgboost's best error=0.0056,\tbest estimator xgboost's best error=0.0056\n",
      "[flaml.automl: 09-16 17:46:33] {2878} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:33] {3055} INFO -  at 5.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
      "[flaml.automl: 09-16 17:46:33] {2878} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:34] {3055} INFO -  at 6.7s,\testimator xgboost's best error=0.0023,\tbest estimator xgboost's best error=0.0023\n",
      "[flaml.automl: 09-16 17:46:34] {2878} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:35] {3055} INFO -  at 7.7s,\testimator xgboost's best error=0.0023,\tbest estimator xgboost's best error=0.0023\n",
      "[flaml.automl: 09-16 17:46:35] {2878} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:36] {3055} INFO -  at 8.7s,\testimator xgboost's best error=0.0004,\tbest estimator xgboost's best error=0.0004\n",
      "[flaml.automl: 09-16 17:46:36] {2878} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:38] {3055} INFO -  at 10.4s,\testimator xgboost's best error=0.0004,\tbest estimator xgboost's best error=0.0004\n",
      "[flaml.automl: 09-16 17:46:38] {2878} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:39] {3055} INFO -  at 11.5s,\testimator xgboost's best error=0.0004,\tbest estimator xgboost's best error=0.0004\n",
      "[flaml.automl: 09-16 17:46:39] {2878} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:41] {3055} INFO -  at 13.1s,\testimator xgboost's best error=0.0002,\tbest estimator xgboost's best error=0.0002\n",
      "[flaml.automl: 09-16 17:46:41] {2878} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:42] {3055} INFO -  at 14.6s,\testimator xgboost's best error=0.0002,\tbest estimator xgboost's best error=0.0002\n",
      "[flaml.automl: 09-16 17:46:42] {2878} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:45] {3055} INFO -  at 17.9s,\testimator xgboost's best error=0.0002,\tbest estimator xgboost's best error=0.0002\n",
      "[flaml.automl: 09-16 17:46:45] {2878} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:47] {3055} INFO -  at 19.8s,\testimator xgboost's best error=0.0002,\tbest estimator xgboost's best error=0.0002\n",
      "[flaml.automl: 09-16 17:46:47] {2878} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:51] {3055} INFO -  at 23.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:46:51] {2878} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 09-16 17:46:52] {3055} INFO -  at 24.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:46:52] {2878} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:04] {3055} INFO -  at 36.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:04] {2878} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:05] {3055} INFO -  at 37.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:05] {2878} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:17] {3055} INFO -  at 49.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:17] {2878} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:19] {3055} INFO -  at 51.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:19] {2878} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:23] {3055} INFO -  at 55.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:23] {2878} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:25] {3055} INFO -  at 57.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:25] {2878} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:34] {3055} INFO -  at 66.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:34] {2878} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:35] {3055} INFO -  at 67.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:35] {2878} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:41] {3055} INFO -  at 73.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:41] {2878} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:43] {3055} INFO -  at 75.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:43] {2878} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:48] {3055} INFO -  at 80.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:48] {2878} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 09-16 17:47:50] {3055} INFO -  at 82.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:47:50] {2878} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 09-16 17:48:00] {3055} INFO -  at 92.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:48:00] {2878} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 09-16 17:48:10] {3055} INFO -  at 102.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:48:10] {2878} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 09-16 17:48:27] {3055} INFO -  at 119.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:48:27] {2878} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 09-16 17:48:59] {3055} INFO -  at 151.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:48:59] {2878} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 09-16 17:49:09] {3055} INFO -  at 161.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-16 17:49:09] {2878} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 09-16 17:50:39] {3055} INFO -  at 250.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:50:39] {2878} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 09-16 17:50:41] {3055} INFO -  at 253.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:50:41] {2878} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 09-16 17:50:52] {3055} INFO -  at 264.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:50:52] {2878} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 09-16 17:51:17] {3055} INFO -  at 289.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:51:17] {2878} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 09-16 17:51:41] {3055} INFO -  at 313.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:51:41] {2878} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 09-16 17:51:53] {3055} INFO -  at 325.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:51:53] {2878} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 09-16 17:52:01] {3055} INFO -  at 333.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:52:01] {2878} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 09-16 17:52:26] {3055} INFO -  at 358.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:52:26] {2878} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 09-16 17:53:14] {3055} INFO -  at 406.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:53:14] {2878} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 09-16 17:53:31] {3055} INFO -  at 423.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:53:31] {2878} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 09-16 17:54:50] {3055} INFO -  at 502.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:54:50] {2878} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 09-16 17:55:02] {3055} INFO -  at 514.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:55:02] {2878} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 09-16 17:55:20] {3055} INFO -  at 532.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:55:20] {2878} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 09-16 17:55:58] {3055} INFO -  at 570.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:55:58] {2878} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 09-16 17:57:42] {3055} INFO -  at 674.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:57:42] {2878} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 09-16 17:57:53] {3055} INFO -  at 685.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:57:53] {2878} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 09-16 17:59:00] {3055} INFO -  at 752.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:59:00] {2878} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 09-16 17:59:12] {3055} INFO -  at 764.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 17:59:12] {2878} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl: 09-16 18:00:35] {3055} INFO -  at 846.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:00:35] {2878} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl: 09-16 18:00:50] {3055} INFO -  at 862.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:00:50] {2878} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 09-16 18:01:07] {3055} INFO -  at 879.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:01:07] {2878} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 09-16 18:01:43] {3055} INFO -  at 915.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:01:43] {2878} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 09-16 18:02:37] {3055} INFO -  at 969.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:02:37] {2878} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 09-16 18:02:56] {3055} INFO -  at 988.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:02:56] {2878} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 09-16 18:03:22] {3055} INFO -  at 1014.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:03:22] {2878} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 09-16 18:04:06] {3055} INFO -  at 1058.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:04:06] {2878} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 09-16 18:06:02] {3055} INFO -  at 1174.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:06:02] {2878} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl: 09-16 18:06:15] {3055} INFO -  at 1187.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:06:15] {2878} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 09-16 18:07:05] {3055} INFO -  at 1237.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:07:05] {2878} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 09-16 18:07:33] {3055} INFO -  at 1265.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:07:33] {2878} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl: 09-16 18:07:40] {3055} INFO -  at 1272.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:07:40] {2878} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 09-16 18:11:01] {3055} INFO -  at 1473.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:11:01] {2878} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 09-16 18:12:05] {3055} INFO -  at 1537.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:12:05] {2878} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl: 09-16 18:12:21] {3055} INFO -  at 1553.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:12:21] {2878} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 09-16 18:13:01] {3055} INFO -  at 1593.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:13:01] {2878} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 09-16 18:13:24] {3055} INFO -  at 1616.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:13:24] {2878} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 09-16 18:14:08] {3055} INFO -  at 1660.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-16 18:14:08] {2878} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 09-16 18:14:34] {3055} INFO -  at 1686.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:14:34] {2878} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 09-16 18:15:18] {3055} INFO -  at 1730.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:15:18] {2878} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl: 09-16 18:15:37] {3055} INFO -  at 1749.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:15:37] {2878} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl: 09-16 18:16:38] {3055} INFO -  at 1810.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:16:38] {2878} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl: 09-16 18:16:55] {3055} INFO -  at 1827.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:16:55] {2878} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl: 09-16 18:17:21] {3055} INFO -  at 1853.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:17:21] {2878} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl: 09-16 18:17:43] {3055} INFO -  at 1875.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:17:43] {2878} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl: 09-16 18:18:26] {3055} INFO -  at 1918.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:18:26] {2878} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 09-16 18:18:51] {3055} INFO -  at 1943.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:18:51] {2878} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl: 09-16 18:19:11] {3055} INFO -  at 1962.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:19:11] {2878} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl: 09-16 18:19:58] {3055} INFO -  at 2010.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:19:58] {2878} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 09-16 18:20:49] {3055} INFO -  at 2061.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:20:49] {2878} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl: 09-16 18:21:17] {3055} INFO -  at 2089.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:21:17] {2878} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 09-16 18:21:40] {3055} INFO -  at 2112.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:21:40] {2878} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 09-16 18:22:23] {3055} INFO -  at 2155.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:22:23] {2878} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 09-16 18:23:45] {3055} INFO -  at 2237.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:23:45] {2878} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl: 09-16 18:23:58] {3055} INFO -  at 2250.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:23:58] {2878} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl: 09-16 18:24:20] {3055} INFO -  at 2272.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:24:20] {2878} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl: 09-16 18:24:41] {3055} INFO -  at 2293.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:24:41] {2878} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl: 09-16 18:25:08] {3055} INFO -  at 2320.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:25:08] {2878} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 09-16 18:25:47] {3055} INFO -  at 2359.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:25:47] {2878} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl: 09-16 18:26:03] {3055} INFO -  at 2375.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:26:03] {2878} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl: 09-16 18:27:15] {3055} INFO -  at 2447.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:27:15] {2878} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl: 09-16 18:29:25] {3055} INFO -  at 2577.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:29:25] {2878} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl: 09-16 18:29:35] {3055} INFO -  at 2587.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:29:35] {2878} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl: 09-16 18:29:50] {3055} INFO -  at 2602.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:29:50] {2878} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 09-16 18:30:43] {3055} INFO -  at 2655.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:30:43] {2878} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 09-16 18:31:38] {3055} INFO -  at 2710.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:31:38] {2878} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl: 09-16 18:31:51] {3055} INFO -  at 2723.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:31:51] {2878} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 09-16 18:33:08] {3055} INFO -  at 2800.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:33:08] {2878} INFO - iteration 102, current learner xgboost\n",
      "[flaml.automl: 09-16 18:33:22] {3055} INFO -  at 2814.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:33:22] {2878} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 09-16 18:33:42] {3055} INFO -  at 2834.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:33:42] {2878} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl: 09-16 18:34:22] {3055} INFO -  at 2874.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:34:22] {2878} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 09-16 18:34:37] {3055} INFO -  at 2889.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:34:37] {2878} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 09-16 18:35:45] {3055} INFO -  at 2957.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:35:45] {2878} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 09-16 18:36:02] {3055} INFO -  at 2974.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:36:02] {2878} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl: 09-16 18:37:04] {3055} INFO -  at 3036.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-16 18:37:04] {2878} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 09-16 18:37:25] {3055} INFO -  at 3057.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:37:25] {2878} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl: 09-16 18:37:51] {3055} INFO -  at 3083.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:37:51] {2878} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl: 09-16 18:37:56] {3055} INFO -  at 3088.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:37:56] {2878} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl: 09-16 18:39:33] {3055} INFO -  at 3185.4s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:39:33] {2878} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 09-16 18:40:16] {3055} INFO -  at 3228.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:40:16] {2878} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl: 09-16 18:40:21] {3055} INFO -  at 3233.9s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:40:21] {2878} INFO - iteration 115, current learner xgboost\n",
      "[flaml.automl: 09-16 18:40:31] {3055} INFO -  at 3243.0s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:40:31] {2878} INFO - iteration 116, current learner xgboost\n",
      "[flaml.automl: 09-16 18:40:57] {3055} INFO -  at 3269.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:40:57] {2878} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl: 09-16 18:41:17] {3055} INFO -  at 3289.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:41:17] {2878} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl: 09-16 18:41:44] {3055} INFO -  at 3316.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:41:44] {2878} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl: 09-16 18:41:49] {3055} INFO -  at 3321.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:41:49] {2878} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl: 09-16 18:43:10] {3055} INFO -  at 3402.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:43:10] {2878} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl: 09-16 18:43:17] {3055} INFO -  at 3409.2s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:43:17] {2878} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl: 09-16 18:44:24] {3055} INFO -  at 3476.6s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:44:24] {2878} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl: 09-16 18:44:47] {3055} INFO -  at 3499.5s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:44:47] {2878} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl: 09-16 18:44:58] {3055} INFO -  at 3510.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:44:58] {2878} INFO - iteration 125, current learner xgboost\n",
      "[flaml.automl: 09-16 18:45:07] {3055} INFO -  at 3519.7s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:45:07] {2878} INFO - iteration 126, current learner xgboost\n",
      "[flaml.automl: 09-16 18:45:37] {3055} INFO -  at 3549.1s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:45:37] {2878} INFO - iteration 127, current learner xgboost\n",
      "[flaml.automl: 09-16 18:45:48] {3055} INFO -  at 3560.8s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:45:48] {2878} INFO - iteration 128, current learner xgboost\n",
      "[flaml.automl: 09-16 18:46:29] {3055} INFO -  at 3601.3s,\testimator xgboost's best error=0.0000,\tbest estimator xgboost's best error=0.0000\n",
      "[flaml.automl: 09-16 18:46:36] {3315} INFO - retrain xgboost for 7.1s\n",
      "[flaml.automl: 09-16 18:46:36] {3322} INFO - retrained model: XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.7648387000381272, colsample_bynode=1,\n",
      "              colsample_bytree=0.8107640410839736, gamma=0, gpu_id=-1,\n",
      "              grow_policy='lossguide', importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.18101175684221335,\n",
      "              max_delta_step=0, max_depth=0, max_leaves=99,\n",
      "              min_child_weight=0.04274701165602129, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=1654, n_jobs=-1,\n",
      "              num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0.032549565253048134, reg_lambda=0.9032450259465333,\n",
      "              scale_pos_weight=1, subsample=1.0, tree_method='hist',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=0)\n",
      "[flaml.automl: 09-16 18:46:36] {2617} INFO - fit succeeded\n",
      "[flaml.automl: 09-16 18:46:36] {2618} INFO - Time taken to find the best model: 3549.1240861415863\n",
      "[flaml.automl: 09-16 18:46:36] {2629} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=3600, estimator_list=['xgboost'],\n",
    "          log_file_name='automl.log', log_type='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3411e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.980\n",
      "f1 score: 0.803\n",
      "Accuracy: 92.79%\n",
      "Precision: 88.28%\n",
      "Detection rate: 73.67%\n",
      "False alarm rate: 2.4405313561940067%\n",
      "MCC: 0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "y_pred_proba = automl.predict_proba(X_test)[:, 1]\n",
    "metrics_display(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4704698",
   "metadata": {},
   "source": [
    "#### 2.3 Develop AutoML API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3530093",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78923fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_hp = {\n",
    "         \"learning_rate\": {\n",
    "             \"domain\": tune.loguniform(lower=0.01, upper=20.0),\n",
    "             \"init_value\": 1\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from flaml import tune\n",
    "from flaml import AutoML\n",
    "\n",
    "@tool(\"AutoML-LightGBM\")\n",
    "def auto_machine_learning(time_budget: float, metric: str, custom_hp: dict) -> str:\n",
    "    \"\"\"Hyperparameter tuning with FLAML library. The tunable hyperparameters for LightGBM are: \n",
    "    n_estimators, num_leaves, min_child_samples, learning_rate, \n",
    "    log_max_bin (logarithm of (max_bin + 1) with base 2), \n",
    "    colsample_bytree, reg_alpha, reg_lambda.\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    time_budget: A float number of the time budget in seconds.\n",
    "    metric: The optimization metric. \n",
    "            Built-in metric:\n",
    "                'accuracy': 1 - accuracy as the corresponding metric to minimize.\n",
    "                'roc_auc': minimize 1 - roc_auc_score. \n",
    "                'f1': minimize 1 - f1_score.\n",
    "            User-defined function:\n",
    "                A customized metric function that requires the following (input) signature, and returns the input \n",
    "                config’s value in terms of the metric you want to minimize, and a dictionary of auxiliary information \n",
    "                at your choice:\n",
    "                \n",
    "                    def custom_metric(\n",
    "                        X_val, y_val, estimator, labels,\n",
    "                        X_train, y_train, weight_val=None, weight_train=None,\n",
    "                        config=None, groups_val=None, groups_train=None,\n",
    "                    ):\n",
    "                        return metric_to_minimize, metrics_to_log\n",
    "                        \n",
    "                For example:\n",
    "                \n",
    "                    def custom_metric(\n",
    "                        X_val, y_val, estimator, labels,\n",
    "                        X_train, y_train, weight_val=None, weight_train=None,\n",
    "                        *args,\n",
    "                    ):\n",
    "                        from sklearn.metrics import log_loss\n",
    "                        import time\n",
    "\n",
    "                        start = time.time()\n",
    "                        y_pred = estimator.predict_proba(X_val)\n",
    "                        pred_time = (time.time() - start) / len(X_val)\n",
    "                        val_loss = log_loss(y_val, y_pred, labels=labels, sample_weight=weight_val)\n",
    "                        y_pred = estimator.predict_proba(X_train)\n",
    "                        train_loss = log_loss(y_train, y_pred, labels=labels, sample_weight=weight_train)\n",
    "                        alpha = 0.5\n",
    "\n",
    "    custom_hp: The custom search space specified by user.It is a nested dict with keys being hyperparameter names, \n",
    "               and values are dicts of info (\"domain\" and \"init_value\") about the search space associated with the \n",
    "               hyperparameter.\n",
    "               \n",
    "               \n",
    "               See the example below for the commonly used types of domains.\n",
    "               \n",
    "                # Sample a float uniformly between -5.0 and -1.0\n",
    "                tune.uniform(-5, -1),\n",
    "\n",
    "                # Sample a float uniformly between 3.2 and 5.4,\n",
    "                # rounding to increments of 0.2\n",
    "                tune.quniform(3.2, 5.4, 0.2),\n",
    "\n",
    "                # Sample a float uniformly between 0.0001 and 0.01, while\n",
    "                # sampling in log space\n",
    "                tune.loguniform(1e-4, 1e-2),\n",
    "\n",
    "                # Sample a float uniformly between 0.0001 and 0.1, while\n",
    "                # sampling in log space and rounding to increments of 0.00005\n",
    "                tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "\n",
    "                # Sample a random float from a normal distribution with\n",
    "                # mean=10 and sd=2\n",
    "                tune.randn(10, 2),\n",
    "\n",
    "                # Sample a random float from a normal distribution with\n",
    "                # mean=10 and sd=2, rounding to increments of 0.2\n",
    "                tune.qrandn(10, 2, 0.2),\n",
    "\n",
    "                # Sample a integer uniformly between -9 (inclusive) and 15 (exclusive)\n",
    "                tune.randint(-9, 15),\n",
    "\n",
    "                # Sample a random uniformly between -21 (inclusive) and 12 (inclusive (!))\n",
    "                # rounding to increments of 3 (includes 12)\n",
    "                tune.qrandint(-21, 12, 3),\n",
    "\n",
    "                # Sample a integer uniformly between 1 (inclusive) and 10 (exclusive),\n",
    "                # while sampling in log space\n",
    "                tune.lograndint(1, 10),\n",
    "\n",
    "                # Sample a integer uniformly between 2 (inclusive) and 10 (inclusive (!)),\n",
    "                # while sampling in log space and rounding to increments of 2\n",
    "                tune.qlograndint(2, 10, 2),\n",
    "                \n",
    "                # Sample an option uniformly from the specified choices\n",
    "                tune.choice([\"a\", \"b\", \"c\"])  \n",
    "\n",
    "                \n",
    "    Outputs:\n",
    "    --------\n",
    "    record: log of tuning process, including the tuning history and the currently found \n",
    "            best configurations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # AutoML object\n",
    "    automl = AutoML()\n",
    "    \n",
    "    # Tuning config\n",
    "    config = {\n",
    "        'task': 'classification',\n",
    "        'metric': metric,\n",
    "        'time_budget': time_budget,\n",
    "        'estimator_list': ['lgbm'],\n",
    "        'custom_hp': {'lgbm': custom_hp},\n",
    "        'log_file_name': 'automl.log',\n",
    "    }\n",
    "    \n",
    "    # Fitting\n",
    "    automl.fit(X_train, y_train, **config)\n",
    "    opt['model'] = automl\n",
    "    \n",
    "    # Tuning logs\n",
    "    with open(\"automl.log\", \"r\") as txt_file:\n",
    "        log = txt_file.readlines()\n",
    "    record = {\n",
    "        'log': log,\n",
    "        'best config': automl.best_config\n",
    "    }\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222167c7",
   "metadata": {},
   "source": [
    "#### Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1707b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import tune\n",
    "time_budget = 10\n",
    "metric = 'accuracy'\n",
    "    \n",
    "custom_hp = {\n",
    "         \"learning_rate\": {\n",
    "             \"domain\": tune.loguniform(lower=0.01, upper=1),\n",
    "             \"init_value\": 0.1\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc1380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record = auto_machine_learning(time_budget, metric, custom_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247ff6d",
   "metadata": {},
   "source": [
    "#### 2.4 Dataframe profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_characteristics_report(df, num_feats, bin_feats, nom_feats):\n",
    "    \n",
    "    # Last column is the label\n",
    "    target = df.iloc[:, -1]\n",
    "    features = df.iloc[:, :-1]\n",
    "\n",
    "    # General dataset info\n",
    "    num_instances = len(df)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    # Label class analysis\n",
    "    class_counts = target.value_counts()\n",
    "    class_distribution = class_counts/num_instances\n",
    "    if any(class_distribution<0.3) or any(class_distribution>0.7):\n",
    "        class_imbalance = True\n",
    "    else:\n",
    "        class_imbalance = False\n",
    "    \n",
    "    # Create a text report\n",
    "    report = f\"\"\"Data Characteristics Report:\n",
    "\n",
    "- General information:\n",
    "  - Number of Instances: {num_instances}\n",
    "  - Number of Features: {num_features}\n",
    "\n",
    "- Class distribution analysis:\n",
    "  - Class Distribution: {class_distribution.to_string()}\n",
    "  {'Warning: Class imbalance detected.' if class_imbalance else ''}\n",
    "\n",
    "- Feature analysis:\n",
    "  - Feature names: {features.columns.to_list()}\n",
    "  - Number of numerical features: {len(num_feats)}\n",
    "  - Number of binary features: {len(bin_feats)}\n",
    "  - Binary feature names: {bin_feats}\n",
    "  - Number of nominal features: {len(nom_feats)}\n",
    "  - Nominal feature names: {nom_feats}\n",
    "\"\"\"\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609207cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "print(data_characteristics_report(train, continuous_features, binary_features, nominal_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c56b1",
   "metadata": {},
   "source": [
    "#### Agent testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb080455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "# llm = AzureChatOpenAI(openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "#             openai_api_version=\"2023-03-15-preview\",\n",
    "#             openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "#             openai_api_type=\"azure\",\n",
    "#             deployment_name=\"gpt-35-turbo-0301\")\n",
    "\n",
    "# # Load the language model used to control the agent.\n",
    "llm = AzureOpenAI(\n",
    "        openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "        openai_api_version=\"2023-03-15-preview\",\n",
    "        openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "        openai_api_type=\"azure\",\n",
    "        model_name=\"text-davinci-003\",\n",
    "        deployment_name='deployment-5af509f3323342ee919481751c6f8b7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "# Define agent\n",
    "agent = initialize_agent([auto_machine_learning], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdee842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = f\"\"\"Your task is to use AutoML tool to find the best binary classification model \n",
    "that can detect network intrusions based on collected features. The dataset you will be using \n",
    "captures various features of network connections, representing different types of cyber \n",
    "attacks (dos, r2l, u2r, probe) as well as normal connections. However, for the current \n",
    "analysis, your focus is on binary classification, distinguishing between 'normal' (0) and \n",
    "'attack' (1) labels. You will be using LightGBM as the classifier.\n",
    "\n",
    "A summary of the data characteristics are provided below:\n",
    "{data_characteristics_report(train, continuous_features, binary_features, nominal_features)}\n",
    "\n",
    "Instructions:\n",
    "Using the provided data report, your ML expertise, and available AutoML tool, identify the optimal\n",
    "classification model. Iterate as necessary and provide a final summary of the best model and \n",
    "hyperparameters, along with any insights or recommendations for future steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt = f\"\"\"Your task is to use AutoML tool to find the best binary classification model \n",
    "that can detect network intrusions based on collected features. \n",
    "\n",
    "A summary of the data characteristics are provided below:\n",
    "{data_characteristics_report(train, continuous_features, binary_features, nominal_features)}\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the provided data report and domain context.\n",
    "2. Based on the data characteristics and your ML expertise, propose appropriate hyperparameter ranges and \n",
    "their initial values for search.\n",
    "2. Invoke the AutoML tool with the proposed settings.\n",
    "3. Analyze the results returned by FLAML.\n",
    "4. Iterate the process if necessary to improve the model's performance.\n",
    "Provide a final summary of the best model and hyperparameters, along with any insights or recommendations \n",
    "for future steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2630fb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run agent\n",
    "agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612dc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cba05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"how many letters in the word educa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b7177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
